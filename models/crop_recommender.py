# -*- coding: utf-8 -*-
"""Crop_Recommender

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xzeXBZMg_kmtYXsB_ex9hjwkFAFIlcCz
"""
import joblib
import pandas as pd
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder,StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score,mean_squared_error,confusion_matrix,classification_report

project_root = Path(__file__).parent.parent
crop_recommendation_path = project_root / "datasets" / "Crop_recommendation.csv"
place_path = project_root / "datasets" / "place.csv"

df = pd.read_csv(crop_recommendation_path)   
df_place = pd.read_csv(place_path)   

le_crop = LabelEncoder()
df["label_encoded"] = le_crop.fit_transform(df["label"])

# Define thresholds for nutrient levels (these are example thresholds, adjust as needed)
n_low_threshold = 50
n_medium_threshold = 100
p_low_threshold = 30
p_medium_threshold = 60
k_low_threshold = 30
k_medium_threshold = 60

# Function to categorize nutrient levels
def categorize_nutrient(value, low_threshold, medium_threshold):
    if value <= low_threshold:
        return 'Low'
    elif value <= medium_threshold:
        return 'Medium'
    else:
        return 'High'

# Apply categorization to create new columns
df['N_category'] = df['N'].apply(lambda x: categorize_nutrient(x, n_low_threshold, n_medium_threshold))
df['P_category'] = df['P'].apply(lambda x: categorize_nutrient(x, p_low_threshold, p_medium_threshold))
df['K_category'] = df['K'].apply(lambda x: categorize_nutrient(x, k_low_threshold, k_medium_threshold))

# Encode the categorical nutrient columns using LabelEncoder
le_nutrient = LabelEncoder()
df['N_encoded'] = le_nutrient.fit_transform(df['N_category'])
df['P_encoded'] = le_nutrient.fit_transform(df['P_category'])
df['K_encoded'] = le_nutrient.fit_transform(df['K_category'])


# display(df[['N', 'N_category', 'N_encoded', 'P', 'P_category', 'P_encoded', 'K', 'K_category', 'K_encoded']])

def get_dominant_nutrient_level(row, nutrient_type):
     nutrient_cols = [col for col in row.index if nutrient_type in col]
     return row[nutrient_cols].idxmax()

df_place['Dominant_N'] = df_place.apply(lambda row: get_dominant_nutrient_level(row, 'Nitrogen'), axis=1)
df_place['Dominant_P'] = df_place.apply(lambda row: get_dominant_nutrient_level(row, 'Phosphorous'), axis=1)
df_place['Dominant_K'] = df_place.apply(lambda row: get_dominant_nutrient_level(row, 'Potassium'), axis=1)


state_nutrient_map = df_place.set_index('State/UT')[['Dominant_N', 'Dominant_P', 'Dominant_K']].T.to_dict('dict')

# Display the dictionary (first few items) to verify
print("State Nutrient Mapping:")
for i, (state, nutrients) in enumerate(state_nutrient_map.items()):
    print(f"{state}: {nutrients}")
    if i > 5: # Display only first 5 for brevity
        break

X = df[['N_encoded', 'P_encoded', 'K_encoded', 'temperature', 'humidity']]
Y = df['label_encoded'] # Use the label_encoded column from Step 1

X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=42)

sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

xgb=XGBClassifier(random_state=42)
xgb.fit(X_train,Y_train)

Y_pred_xgb=xgb.predict(X_test)

Y_pred_xgb

print('accuracy score:',accuracy_score(Y_test,Y_pred_xgb))
print('mean_squared_error:',mean_squared_error(Y_test,Y_pred_xgb))
print('classification report:',classification_report(Y_test,Y_pred_xgb))

df.head()

def predict_crop(state, temperature, humidity):
    """
    Predicts the best crop based on state, temperature, and humidity.

    Args:
        state (str): The name of the state.
        temperature (float): The temperature.
        humidity (float): The humidity.

    Returns:
        str: The predicted crop label.
        str: An error message if the state is not found or other issues occur.
    """
    # Get dominant nutrient levels for the state
    if state not in state_nutrient_map:
        return None, f"Error: State '{state}' not found in the nutrient data."

    dominant_nutrients = state_nutrient_map[state]
    dominant_n_str = dominant_nutrients['Dominant_N']
    dominant_p_str = dominant_nutrients['Dominant_P']
    dominant_k_str = dominant_nutrients['Dominant_K']

    # Map dominant nutrient level strings to the categories used in training ('Low', 'Medium', 'High')
    def simplify_nutrient_level(level_string):
        if 'Low' in level_string:
            return 'Low'
        elif 'M' in level_string:
            return 'Medium'
        elif 'High' in level_string or 'H' in level_string or 'VH' in level_string:
            return 'High'
        else:
            return 'Unknown'

    n_category = simplify_nutrient_level(dominant_n_str)
    p_category = simplify_nutrient_level(dominant_p_str)
    k_category = simplify_nutrient_level(dominant_k_str)

    # Encode the categorical nutrient levels
    try:
        n_encoded = le_nutrient.transform([n_category])[0]
        p_encoded = le_nutrient.transform([p_category])[0]
        k_encoded = le_nutrient.transform([k_category])[0]
    except ValueError as e:
         return None, f"Error encoding nutrient categories: {e}. Make sure le_nutrient is fitted on 'Low', 'Medium', 'High'."
    except AttributeError:
         return None, "Error: le_nutrient is not defined. Please ensure the LabelEncoder for nutrients is fitted."


    # Prepare input data for prediction
    input_data = pd.DataFrame([{
        'N_encoded': n_encoded,
        'P_encoded': p_encoded,
        'K_encoded': k_encoded,
        'temperature': temperature,
        'humidity': humidity
    }])

    # Define the columns to scale - these should match the columns the scaler was fitted on
    # Based on the error, this includes the encoded nutrient columns
    cols_to_scale = ['N_encoded', 'P_encoded', 'K_encoded', 'temperature', 'humidity']

    # Scale the input data using the fitted scaler
    try:
        input_data[cols_to_scale] = sc.transform(input_data[cols_to_scale])
    except AttributeError:
        return None, "Error: scaler is not defined. Please ensure the StandardScaler is fitted."
    except ValueError as e:
         return None, f"Error during scaling: {e}. Make sure the columns in input_data match those the scaler was fitted on."


    # Predict the crop
    try:
        predicted_label_encoded = xgb.predict(input_data)[0]
    except AttributeError:
        return None, "Error: xgb_model is not defined. Please ensure the XGBoost model is trained."


    # Inverse transform the predicted label to get the crop name
    try:
        predicted_crop = le_crop.inverse_transform([predicted_label_encoded])[0]
    except AttributeError:
        return None, "Error: le_crop is not defined. Please ensure the LabelEncoder for crops is fitted."
    except ValueError:
         return None, f"Error: Could not inverse transform predicted label {predicted_label_encoded}. Make sure le_crop is fitted correctly."


    return predicted_crop
# print(predict_crop("West Bengal", 30, 95))

# Example usage (replace with your actual trained model, maps, and scaler)
# Make sure you have run the cells to define xgb_model, state_nutrient_map, le_nutrient, and scaler

# predicted_crop, error = predict_crop("Bihar", 25.0, 70.0) # Now call with only 3 arguments

# if error:
#     print(error)
# else:
#     print(f"The predicted best crop is: {predicted_crop}")

# import random

# # Get a list of states from the state_nutrient_map
# available_states = list(state_nutrient_map.keys())

# # Select a random state
# random_state = random.choice(available_states)

# # Generate random temperature and humidity within a reasonable range
# # (Based on the distribution of temperature and humidity in your training data)
# random_temperature = random.uniform(10.0, 40.0) # Example range, adjust if needed
# random_humidity = random.uniform(40.0, 95.0) # Example range, adjust if needed

# print(f"Using random test case:")
# print(f"State: {random_state}")
# print(f"Temperature: {random_temperature:.2f}Â°C")
# print(f"Humidity: {random_humidity:.2f}%")

# Use the predict_crop function with the random inputs
# predicted_crop, error = predict_crop(random_state, random_temperature, random_humidity)

# if error:
#     print(error)
# else:
#     print(f"\nPredicted best crop: {predicted_crop}")

#Creatinig a dictionary of all the components to be saved
crop_model_components = {
    "model": xgb,
    "scaler": sc,
    "le_crop": le_crop,
    "le_nutrient": le_nutrient
}

joblib.dump(crop_model_components, "crop_recommender_components.joblib")

print("Model, scaler, and encoders saved to crop_recommender_components.joblib")

